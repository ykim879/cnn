{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "Using pytorch nn, the code will build cnn from scratch\n",
    "## Dataset\n",
    "data set will be black and white picture (inchannel = 1), where capture basic places with labels. The size of the data is 64 x 64.\n",
    "##  nn liabraries that are going to be used in the project\n",
    "### nn.Module\n",
    "This is the basic class for all neaural network modules. all neaural network built by  nn should be subcalss of this class\n",
    "### nn.Conv2\n",
    "2d convolutional process where the params are (in_channel, out_channel, kernel_size, ...). Since our image is 2d we will do 2d convolution.\n",
    "### nn.MaxPool2d\n",
    "2d Maxpooling. from 2d kernel, pick max value on each kernel.\n",
    "### nn.ReLU\n",
    "Applies recifiedlinear unit function. If the input is negative, it is zero, otherwise the output will be input.\n",
    "### nn.Linear\n",
    "Applies linear transformation (y = xA**T + b) on input size and output size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary liabraries\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architectural Design\n",
    "1. (2d convolutional -> max pooling with 3x3 kenel -> relu) \n",
    "2. (2d convolution -> max pooling with 3x3 kernel -> relu)\n",
    "3. two fully connected layers\n",
    "\n",
    "### Loss Criterion\n",
    "To calculate the difference, it used 'mean' reduction in the loss criterion by using method of cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Init function to define the layers and loss function\n",
    "\n",
    "        Note:Read Pytorch documention to understand what it means\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential()\n",
    "        # input: 1x(64x64)\n",
    "        self.conv_layers.add_module(\"conv_1\", nn.Conv2d(1, 10, kernel_size=5))\n",
    "        # output/input: 10 x (60x60)\n",
    "        self.conv_layers.add_module(\"maxpool1\", nn.MaxPool2d(kernel_size=3))\n",
    "        self.conv_layers.add_module(\"relu_1\", nn.ReLU())\n",
    "        # output: 10 x (20 x 20)\n",
    "\n",
    "        # input: 10 x (20 x 20)\n",
    "        self.conv_layers.add_module(\"conv_2\", nn.Conv2d(10, 20, kernel_size=5))\n",
    "        # output/input: 20 x (16x16)\n",
    "        self.conv_layers.add_module(\"maxpool2\", nn.MaxPool2d(kernel_size=3))\n",
    "        self.conv_layers.add_module(\"relu_2\",  nn.ReLU())\n",
    "        # output: 20 x (5 x 5)\n",
    "\n",
    "        self.conv_layers.add_module(\"flatten\",  nn.Flatten())\n",
    "        self.conv_layers.add_module(\"relu_3\",  nn.ReLU())\n",
    "        # output: 20 x 5 x 5 = 500\n",
    "\n",
    "        # this is fully connected layers\n",
    "        self.fc_layers = nn.Sequential()\n",
    "        self.fc_layers.add_module(\"linear_1\", nn.Linear(in_features=500, out_features=100))\n",
    "        self.fc_layers.add_module(\"linear_2\", nn.Linear(in_features=100, out_features=15))\n",
    "\n",
    "        self.loss_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        -   x: the input image [Dim: (N,C,H,W)] : data type = Tensor\n",
    "        Returns:\n",
    "        -   y: the output (raw scores) of the net [Dim: (N,15)] : data type = Tensor\n",
    "        \"\"\"\n",
    "        return self.fc_layers(self.conv_layers(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchNorm2d\n",
    "Applied 4d Batch normalization. The mean and standard-deviation are calculated per-dimension over the mini-batches of 2D inputs with additional channel dimension and γ\\gammaγ and β\\betaβ are learnable parameter vectors of size of the input.\n",
    "funtion is described on the website: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "\n",
    "        self.fc_layers = nn.Sequential()\n",
    "\n",
    "        self.conv_layers = nn.Sequential()\n",
    "        self.conv_layers.add_module(\"conv_1\", torch.nn.Conv2d(1, 10, kernel_size=5))\n",
    "        self.conv_layers.add_module(\"BN1\", nn.BatchNorm2d(num_features=10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        self.conv_layers.add_module(\"maxpool1\", torch.nn.MaxPool2d(kernel_size=3, padding=1, stride = 2))\n",
    "        self.conv_layers.add_module(\"relu_1\", torch.nn.ReLU())\n",
    "        \n",
    "        self.conv_layers.add_module(\"conv_2\", torch.nn.Conv2d(10, 20, kernel_size=5))\n",
    "        self.conv_layers.add_module(\"BN2\", nn.BatchNorm2d(num_features=20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        self.conv_layers.add_module(\"maxpool2\", torch.nn.MaxPool2d(kernel_size=3, padding=1, stride= 2))\n",
    "        self.conv_layers.add_module(\"relu_2\", torch.nn.ReLU())\n",
    "        \n",
    "        self.conv_layers.add_module(\"dropout\", torch.nn.Dropout())\n",
    "        self.conv_layers.add_module(\"conv_3\", torch.nn.Conv2d(20, 50, kernel_size=5))\n",
    "        self.conv_layers.add_module(\"maxpool3\", torch.nn.MaxPool2d(kernel_size=3, padding=1, stride= 2))\n",
    "        self.conv_layers.add_module(\"relu_3\", torch.nn.ReLU())\n",
    "        self.conv_layers.add_module(\"flatten\", torch.nn.Flatten())\n",
    "\n",
    "\n",
    "        self.fc_layers.add_module(\"linear_1\", nn.Linear(in_features=1250, out_features=500))\n",
    "        self.fc_layers.add_module(\"linear_2\", nn.Linear(in_features=500, out_features=15))\n",
    "\n",
    "        self.loss_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform the forward pass with the net\n",
    "\n",
    "        Args:\n",
    "        -   x: the input image [Dim: (N,C,H,W)]\n",
    "        Returns:\n",
    "        -   y: the output (raw scores) of the net [Dim: (N,15)]\n",
    "        \"\"\"\n",
    "        \n",
    "        conv_output = self.conv_layers(x)\n",
    "        model_output = self.fc_layers(conv_output)\n",
    "\n",
    "        return model_output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}