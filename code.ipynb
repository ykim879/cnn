{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "Using pytorch nn, the code will build cnn from scratch\n",
    "## Dataset\n",
    "data set will be black and white picture (inchannel = 1), where capture basic places with labels. The size of the data is 64 x 64.\n",
    "##  nn liabraries that are going to be used in the project\n",
    "### nn.Module\n",
    "This is the basic class for all neaural network modules. all neaural network built by  nn should be subcalss of this class\n",
    "### nn.Conv2\n",
    "2d convolutional process where the params are (in_channel, out_channel, kernel_size, ...). Since our image is 2d we will do 2d convolution.\n",
    "### nn.MaxPool2d\n",
    "2d Maxpooling. from 2d kernel, pick max value on each kernel.\n",
    "### nn.ReLU\n",
    "Applies recifiedlinear unit function. If the input is negative, it is zero, otherwise the output will be input.\n",
    "### nn.Linear\n",
    "Applies linear transformation (y = xA**T + b) on input size and output size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary liabraries\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architectural Design\n",
    "1. (2d convolutional -> max pooling with 3x3 kenel -> relu) \n",
    "2. (2d convolution -> max pooling with 3x3 kernel -> relu)\n",
    "3. two fully connected layers\n",
    "\n",
    "### Loss Criterion\n",
    "To calculate the difference, it used 'mean' reduction in the loss criterion by using method of cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Init function to define the layers and loss function\n",
    "\n",
    "        Note:Read Pytorch documention to understand what it means\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential()\n",
    "        # input: 1x(64x64)\n",
    "        self.conv_layers.add_module(\"conv_1\", nn.Conv2d(1, 10, kernel_size=5))\n",
    "        # output/input: 10 x (60x60)\n",
    "        self.conv_layers.add_module(\"maxpool1\", nn.MaxPool2d(kernel_size=3))\n",
    "        self.conv_layers.add_module(\"relu_1\", nn.ReLU())\n",
    "        # output: 10 x (20 x 20)\n",
    "\n",
    "        # input: 10 x (20 x 20)\n",
    "        self.conv_layers.add_module(\"conv_2\", nn.Conv2d(10, 20, kernel_size=5))\n",
    "        # output/input: 20 x (16x16)\n",
    "        self.conv_layers.add_module(\"maxpool2\", nn.MaxPool2d(kernel_size=3))\n",
    "        self.conv_layers.add_module(\"relu_2\",  nn.ReLU())\n",
    "        # output: 20 x (5 x 5)\n",
    "\n",
    "        self.conv_layers.add_module(\"flatten\",  nn.Flatten())\n",
    "        self.conv_layers.add_module(\"relu_3\",  nn.ReLU())\n",
    "        # output: 20 x 5 x 5 = 500\n",
    "\n",
    "        # this is fully connected layers\n",
    "        self.fc_layers = nn.Sequential()\n",
    "        self.fc_layers.add_module(\"linear_1\", nn.Linear(in_features=500, out_features=100))\n",
    "        self.fc_layers.add_module(\"linear_2\", nn.Linear(in_features=100, out_features=15))\n",
    "\n",
    "        self.loss_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        -   x: the input image [Dim: (N,C,H,W)] : data type = Tensor\n",
    "        Returns:\n",
    "        -   y: the output (raw scores) of the net [Dim: (N,15)] : data type = Tensor\n",
    "        \"\"\"\n",
    "        return self.fc_layers(self.conv_layers(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchNorm2d\n",
    "Applied 4d Batch normalization. The mean and standard-deviation are calculated per-dimension over the mini-batches of 2D inputs with additional channel dimension and γ\\gammaγ and β\\betaβ are learnable parameter vectors of size of the input.\n",
    "funtion is described on the website: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "\n",
    "        self.fc_layers = nn.Sequential()\n",
    "\n",
    "        self.conv_layers = nn.Sequential()\n",
    "        self.conv_layers.add_module(\"conv_1\", nn.Conv2d(1, 10, kernel_size=5))\n",
    "        self.conv_layers.add_module(\"BN1\", nn.BatchNorm2d(num_features=10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        self.conv_layers.add_module(\"maxpool1\", nn.MaxPool2d(kernel_size=3, padding=1, stride = 2))\n",
    "        self.conv_layers.add_module(\"relu_1\", nn.ReLU())\n",
    "        \n",
    "        self.conv_layers.add_module(\"conv_2\", nn.Conv2d(10, 20, kernel_size=5))\n",
    "        self.conv_layers.add_module(\"BN2\", nn.BatchNorm2d(num_features=20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        self.conv_layers.add_module(\"maxpool2\", nn.MaxPool2d(kernel_size=3, padding=1, stride= 2))\n",
    "        self.conv_layers.add_module(\"relu_2\", nn.ReLU())\n",
    "        \n",
    "        self.conv_layers.add_module(\"dropout\", nn.Dropout())\n",
    "        self.conv_layers.add_module(\"conv_3\", nn.Conv2d(20, 50, kernel_size=5))\n",
    "        self.conv_layers.add_module(\"maxpool3\", nn.MaxPool2d(kernel_size=3, padding=1, stride= 2))\n",
    "        self.conv_layers.add_module(\"relu_3\", nn.ReLU())\n",
    "        self.conv_layers.add_module(\"flatten\", nn.Flatten())\n",
    "\n",
    "\n",
    "        self.fc_layers.add_module(\"linear_1\", nn.Linear(in_features=1250, out_features=500))\n",
    "        self.fc_layers.add_module(\"linear_2\", nn.Linear(in_features=500, out_features=15))\n",
    "\n",
    "        self.loss_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform the forward pass with the net\n",
    "\n",
    "        Args:\n",
    "        -   x: the input image [Dim: (N,C,H,W)]\n",
    "        Returns:\n",
    "        -   y: the output (raw scores) of the net [Dim: (N,15)]\n",
    "        \"\"\"\n",
    "        \n",
    "        conv_output = self.conv_layers(x)\n",
    "        model_output = self.fc_layers(conv_output)\n",
    "\n",
    "        return model_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "CNN2(\n  (fc_layers): Sequential(\n    (linear_1): Linear(in_features=1250, out_features=500, bias=True)\n    (linear_2): Linear(in_features=500, out_features=15, bias=True)\n  )\n  (conv_layers): Sequential(\n    (conv_1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n    (BN1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (relu_1): ReLU()\n    (conv_2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n    (BN2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (relu_2): ReLU()\n    (dropout): Dropout(p=0.5, inplace=False)\n    (conv_3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n    (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (relu_3): ReLU()\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (loss_criterion): CrossEntropyLoss()\n)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1 = CNN1()\n",
    "cnn2 = CNN2()\n",
    "cnn1.train()\n",
    "cnn2.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "' Optional Cuda package (personally do not have cuda but you can use cuda to speed up the model)\\nfrom torch import cuda\\nif cuda:\\n    cnn1.cuda()\\n    cnn2.cuda()'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Optional Cuda package (personally do not have cuda but you can use cuda to speed up the model)\n",
    "from torch import cuda\n",
    "if cuda:\n",
    "    cnn1.cuda()\n",
    "    cnn2.cuda()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './model_checkpoints/simple_net/checkpoint.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4275187f37ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./model_checkpoints/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"simple_net\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"checkpoint.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './model_checkpoints/simple_net/checkpoint.pt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from vision.dl_utils import compute_accuracy, compute_loss\n",
    "from vision.image_loader import ImageLoader\n",
    "from vision.my_resnet import MyResNet18\n",
    "from vision.simple_net import SimpleNet\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name: str, fmt: str = \":f\") -> None:\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val: float, n: int = 1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = \"{name} {val\" + self.fmt + \"} ({avg\" + self.fmt + \"})\"\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"Class that stores model training metadata.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        model: Union[SimpleNet, MyResNet18],\n",
    "        optimizer: Optimizer,\n",
    "        model_dir: str,\n",
    "        train_data_transforms: transforms.Compose,\n",
    "        val_data_transforms: transforms.Compose,\n",
    "        batch_size: int = 100,\n",
    "        load_from_disk: bool = True\n",
    "    ) -> None:\n",
    "        self.model_dir = model_dir\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        self.train_dataset = ImageLoader(\n",
    "            data_dir, split=\"train\", transform=train_data_transforms\n",
    "        )\n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        self.val_dataset = ImageLoader(\n",
    "            data_dir, split=\"test\", transform=val_data_transforms\n",
    "        )\n",
    "        self.val_loader = DataLoader(self.val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.train_loss_history = []\n",
    "        self.validation_loss_history = []\n",
    "        self.train_accuracy_history = []\n",
    "        self.validation_accuracy_history = []\n",
    "\n",
    "        # load the model from the disk if it exists\n",
    "        if os.path.exists(model_dir) and load_from_disk:\n",
    "            checkpoint = torch.load(os.path.join(self.model_dir, \"checkpoint.pt\"))\n",
    "            self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "    def save_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Saves the model state and optimizer state on the dict\n",
    "        \"\"\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "            },\n",
    "            os.path.join(self.model_dir, \"checkpoint.pt\"),\n",
    "        )\n",
    "\n",
    "    def run_training_loop(self, num_epochs: int) -> None:\n",
    "        \"\"\"Train for num_epochs, and validate after every epoch.\"\"\"\n",
    "        for epoch_idx in range(num_epochs):\n",
    "\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "\n",
    "            self.train_loss_history.append(train_loss)\n",
    "            self.train_accuracy_history.append(train_acc)\n",
    "\n",
    "            val_loss, val_acc = self.validate()\n",
    "            self.validation_loss_history.append(val_loss)\n",
    "            self.validation_accuracy_history.append(val_acc)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch:{epoch_idx + 1}\"\n",
    "                + f\" Train Loss:{train_loss:.4f}\"\n",
    "                + f\" Val Loss: {val_loss:.4f}\"\n",
    "                + f\" Train Accuracy: {train_acc:.4f}\"\n",
    "                + f\" Validation Accuracy: {val_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "    def train_epoch(self) -> Tuple[float, float]:\n",
    "        \"\"\"Implements the main training loop.\"\"\"\n",
    "        self.model.train()\n",
    "\n",
    "        train_loss_meter = AverageMeter(\"train loss\")\n",
    "        train_acc_meter = AverageMeter(\"train accuracy\")\n",
    "        # loop over each minibatch\n",
    "        for (x, y) in self.train_loader:\n",
    "\n",
    "            n = x.shape[0]\n",
    "            logits = self.model(x)\n",
    "            batch_acc = compute_accuracy(logits, y)\n",
    "            train_acc_meter.update(val=batch_acc, n=n)\n",
    "\n",
    "            batch_loss = compute_loss(self.model, logits, y, is_normalize=True)\n",
    "            train_loss_meter.update(val=float(batch_loss.cpu().item()), n=n)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            batch_loss.backward() #do loss backward\n",
    "            self.optimizer.step() #do optimizer step\n",
    "\n",
    "        return train_loss_meter.avg, train_acc_meter.avg\n",
    "\n",
    "    def validate(self) -> Tuple[float, float]:\n",
    "        \"\"\"Evaluate on held-out split (either val or test)\"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        val_loss_meter = AverageMeter(\"val loss\")\n",
    "        val_acc_meter = AverageMeter(\"val accuracy\")\n",
    "\n",
    "        # loop over whole val set\n",
    "        for (x, y) in self.val_loader:\n",
    "            n = x.shape[0]\n",
    "            logits = self.model(x)\n",
    "\n",
    "            batch_acc = compute_accuracy(logits, y)\n",
    "            val_acc_meter.update(val=batch_acc, n=n)\n",
    "\n",
    "            batch_loss = compute_loss(self.model, logits, y, is_normalize=True)\n",
    "            val_loss_meter.update(val=float(batch_loss.cpu().item()), n=n)\n",
    "\n",
    "        return val_loss_meter.avg, val_acc_meter.avg\n",
    "\n",
    "    def plot_loss_history(self) -> None:\n",
    "        \"\"\"Plots the loss history\"\"\"\n",
    "        plt.figure()\n",
    "        epoch_idxs = range(len(self.train_loss_history))\n",
    "\n",
    "        plt.plot(epoch_idxs, self.train_loss_history, \"-b\", label=\"training\")\n",
    "        plt.plot(epoch_idxs, self.validation_loss_history, \"-r\", label=\"validation\")\n",
    "        plt.title(\"Loss history\")\n",
    "        plt.legend()\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_accuracy(self) -> None:\n",
    "        \"\"\"Plots the accuracy history\"\"\"\n",
    "        plt.figure()\n",
    "        epoch_idxs = range(len(self.train_accuracy_history))\n",
    "        plt.plot(epoch_idxs, self.train_accuracy_history, \"-b\", label=\"training\")\n",
    "        plt.plot(epoch_idxs, self.validation_accuracy_history, \"-r\", label=\"validation\")\n",
    "        plt.title(\"Accuracy history\")\n",
    "        plt.legend()\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insight on CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layers(layers):\n",
    "    \"\"\"\n",
    "    Keep on flattening nn.Sequential objects\n",
    "    \"\"\"\n",
    "\n",
    "    flattened_layers = list()\n",
    "\n",
    "    recurse = False\n",
    "    if isinstance(layers, nn.Linear):\n",
    "        return layers\n",
    "    for elem in layers:\n",
    "        if type(elem) == nn.Sequential:\n",
    "            recurse = True\n",
    "            flattened_layers += list(elem.children())\n",
    "        else:\n",
    "            flattened_layers.append(elem)\n",
    "\n",
    "    if recurse:\n",
    "        return flatten_layers(flattened_layers)\n",
    "\n",
    "    return flattened_layers\n",
    "\n",
    "\n",
    "def extract_model_layers(model: Union[SimpleNet, SimpleNetFinal, MyResNet18]):\n",
    "    # get the CNN sequential\n",
    "    layers = flatten_layers(\n",
    "        list(model.conv_layers.children())\n",
    "        + (\n",
    "            [model.fc_layers]\n",
    "            if isinstance(model.fc_layers, nn.Linear)\n",
    "            else list(model.fc_layers.children())\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # generate counts of different types of layers present in the model\n",
    "    layers_type = [x.__class__.__name__ for x in layers]\n",
    "    layers_count = Counter(layers_type)\n",
    "\n",
    "    # get the total number of parameters which require grad and which do not require grad\n",
    "    num_params_grad = 0\n",
    "    num_params_nograd = 0\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            num_params_grad += param.numel()\n",
    "        else:\n",
    "            num_params_nograd += param.numel()\n",
    "    return (\n",
    "        layers,\n",
    "        layers[-1].out_features,\n",
    "        layers_count,\n",
    "        num_params_grad,\n",
    "        num_params_nograd,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model1 = SimpleNet()\n",
    "    print(extract_model_layers(model1))\n",
    "\n",
    "    model2 = SimpleNetFinal()\n",
    "    print(extract_model_layers(model2))\n",
    "\n",
    "    model3 = MyResNet18()\n",
    "    print(extract_model_layers(model3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}